#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import time
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import joblib
import scipy.sparse as sp
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from src.database import DatabaseConnector
from src.preprocessor import IDSDataPreprocessor
from src.baseline_model import BaselineModel
from src.zero_day_detector import ZeroDayDetector

def load_models():
    """åŠ è½½æ‰€æœ‰éœ€è¦çš„æ¨¡å‹"""
    try:
        # è·å–å½“å‰ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.dirname(current_dir)
        models_dir = os.path.join(root_dir, "models")
        
        # åŠ è½½é¢„å¤„ç†å™¨
        preprocessor_path = os.path.join(models_dir, "preprocessor.joblib")
        if os.path.exists(preprocessor_path):
            print(f"åŠ è½½é¢„å¤„ç†å™¨: {preprocessor_path}")
            preprocessor = joblib.load(preprocessor_path)
        else:
            print(f"é”™è¯¯: é¢„å¤„ç†å™¨æ–‡ä»¶ä¸å­˜åœ¨ {preprocessor_path}")
            return None, None, None, None
        
        # åŠ è½½éš”ç¦»æ£®æ—æ¨¡å‹
        if_path = os.path.join(models_dir, "baseline_isolation_forest.joblib")
        if os.path.exists(if_path):
            print(f"åŠ è½½éš”ç¦»æ£®æ—æ¨¡å‹: {if_path}")
            if_model = joblib.load(if_path)
        else:
            print(f"é”™è¯¯: éš”ç¦»æ£®æ—æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {if_path}")
            return preprocessor, None, None, None
        
        # åŠ è½½K-Meansæ¨¡å‹
        kmeans_path = os.path.join(models_dir, "baseline_kmeans.joblib")
        if os.path.exists(kmeans_path):
            print(f"åŠ è½½K-Meansæ¨¡å‹: {kmeans_path}")
            kmeans_model = joblib.load(kmeans_path)
        else:
            print(f"é”™è¯¯: K-Meansæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {kmeans_path}")
            return preprocessor, if_model, None, None
        
        # åŠ è½½é›¶æ—¥æ£€æµ‹å™¨
        detector_path = os.path.join(models_dir, "zero_day_detector.joblib")
        if os.path.exists(detector_path):
            print(f"åŠ è½½é›¶æ—¥æ£€æµ‹å™¨: {detector_path}")
            detector = joblib.load(detector_path)
        else:
            print(f"è­¦å‘Š: é›¶æ—¥æ£€æµ‹å™¨æ–‡ä»¶ä¸å­˜åœ¨ {detector_path}")
            detector = None
        
        return preprocessor, if_model, kmeans_model, detector
    
    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, None

def get_recent_alerts(db, days=1):
    """è·å–æœ€è¿‘çš„å‘Šè­¦æ•°æ®"""
    alerts_df = db.get_alerts(days=days, include_baseline=False)
    return alerts_df

def detect_zero_day_attacks(alerts, preprocessor, if_model, kmeans_model, detector):
    """
    æ£€æµ‹é›¶æ—¥æ”»å‡»
    
    å‚æ•°:
    - alerts: å¾…æ£€æµ‹çš„å‘Šè­¦æ•°æ®
    - preprocessor: é¢„å¤„ç†å™¨
    - if_model: éš”ç¦»æ£®æ—æ¨¡å‹
    - kmeans_model: Kå‡å€¼èšç±»æ¨¡å‹
    - detector: é›¶æ—¥æ£€æµ‹å™¨
    
    è¿”å›:
    - å¸¦æœ‰æ£€æµ‹ç»“æœçš„DataFrame
    """
    if alerts.empty:
        print("æ²¡æœ‰å¯æ£€æµ‹çš„å‘Šè­¦æ•°æ®")
        return None
    
    try:
        # 1. é¢„å¤„ç†æ•°æ®
        X, processed_df = preprocessor.preprocess(alerts, fit=False)
        feature_names = processed_df.columns.tolist()
        print(f"ä½¿ç”¨çš„ç‰¹å¾ ({len(feature_names)}): {feature_names}")
        
        # 2. ä½¿ç”¨åŸºçº¿æ¨¡å‹æ£€æµ‹å¼‚å¸¸
        # å¦‚æœXæ˜¯ç¨€ç–çŸ©é˜µï¼Œè½¬æ¢ä¸ºå¯†é›†çŸ©é˜µä»¥é€‚åº”éš”ç¦»æ£®æ—æ¨¡å‹
        if sp.issparse(X):
            print("é¢„æµ‹æ—¶å°†ç¨€ç–çŸ©é˜µè½¬æ¢ä¸ºå¯†é›†çŸ©é˜µä»¥é€‚åº”éš”ç¦»æ£®æ—æ¨¡å‹")
            X_dense = X.toarray()
        else:
            X_dense = X
        
        # ä½¿ç”¨éš”ç¦»æ£®æ—æ£€æµ‹å¼‚å¸¸
        if_scores = -if_model.predict(X_dense)  # å°†åˆ†æ•°å–åï¼Œä½¿å¾—é«˜åˆ†è¡¨ç¤ºå¼‚å¸¸
        if_anomalies = if_model.is_anomaly(X_dense)
        
        # ä½¿ç”¨Kå‡å€¼æ£€æµ‹å¼‚å¸¸
        print("é¢„æµ‹æ—¶å°†ç¨€ç–çŸ©é˜µè½¬æ¢ä¸ºå¯†é›†çŸ©é˜µä»¥é€‚åº”Kå‡å€¼æ¨¡å‹")
        kmeans_distances = 1 - kmeans_model.predict(X_dense)  # è½¬æ¢ä¸ºè·ç¦»
        kmeans_anomalies = kmeans_model.is_anomaly(X_dense)
        
        # 3. ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¿®å¤åçš„é›¶æ—¥æ£€æµ‹å™¨
        print("\nä½¿ç”¨ä¿®å¤åçš„é›¶æ—¥æ£€æµ‹å™¨...")
        encoded_features = detector.encode_features(X)
        print(f"ç¼–ç ç‰¹å¾ç»´åº¦: {encoded_features.shape}")
        reconstruction_scores = detector.predict(X)  # ä¿®å¤åçš„å½’ä¸€åŒ–åˆ†æ•°
        raw_errors = detector.predict_raw_errors(X)  # åŸå§‹é‡å»ºè¯¯å·®
        zero_day_anomalies = detector.is_zero_day(X)  # åŸºäºé˜ˆå€¼çš„åˆ¤å®š
        
        print(f"[DEBUG] é›¶æ—¥æ£€æµ‹å™¨ç»“æœ:")
        print(f"  åŸå§‹é‡å»ºè¯¯å·®èŒƒå›´: [{raw_errors.min():.6f}, {raw_errors.max():.6f}]")
        print(f"  å½’ä¸€åŒ–åˆ†æ•°èŒƒå›´: [{reconstruction_scores.min():.6f}, {reconstruction_scores.max():.6f}]")
        print(f"  é›¶æ—¥å€™é€‰æ•°é‡: {zero_day_anomalies.sum()}/{len(zero_day_anomalies)}")
        
        # 4. ç»“åˆæ‰€æœ‰æ£€æµ‹ç»“æœ
        # ğŸ”§ ä¿®å¤ï¼šåŸºçº¿æ¨¡å‹æ£€æµ‹çš„å¼‚å¸¸åˆ¤å®šé€»è¾‘
        # is_anomalyè¿”å›å¸ƒå°”å€¼ï¼ŒTrueè¡¨ç¤ºå¼‚å¸¸ï¼ŒFalseè¡¨ç¤ºæ­£å¸¸
        baseline_anomalies = if_anomalies | kmeans_anomalies
        
        print(f"[DEBUG] åŸºçº¿æ¨¡å‹ç»“æœ:")
        print(f"  éš”ç¦»æ£®æ—å¼‚å¸¸æ•°é‡: {if_anomalies.sum()}/{len(if_anomalies)}")
        print(f"  Kå‡å€¼å¼‚å¸¸æ•°é‡: {kmeans_anomalies.sum()}/{len(kmeans_anomalies)}")
        print(f"  åŸºçº¿å¼‚å¸¸æ•°é‡: {baseline_anomalies.sum()}/{len(baseline_anomalies)}")
        
        # 5. ç»“åˆç»“æœåˆ°åŸå§‹æ•°æ®
        results = alerts.copy()
        results['isolation_forest_score'] = -if_scores  # å°†åˆ†æ•°å–åï¼Œä½¿å¾—é«˜åˆ†è¡¨ç¤ºå¼‚å¸¸
        results['kmeans_distance'] = kmeans_distances
        results['reconstruction_error'] = raw_errors
        results['reconstruction_score_normalized'] = reconstruction_scores
        results['is_baseline_anomaly'] = baseline_anomalies
        results['is_zero_day_candidate'] = zero_day_anomalies
        
        # æ·»åŠ é¢„å¤„ç†åçš„IPå†…å¤–ç½‘ä¿¡æ¯åˆ°ç»“æœä¸­
        if 'src_ip_is_internal' in processed_df.columns:
            results['src_ip_is_internal'] = processed_df['src_ip_is_internal'].values
        if 'dst_ip_is_internal' in processed_df.columns:
            results['dst_ip_is_internal'] = processed_df['dst_ip_is_internal'].values
        if 'device_ip_is_internal' in processed_df.columns:
            results['device_ip_is_internal'] = processed_df['device_ip_is_internal'].values
        
        # 6. ç¡®å®šæœ€ç»ˆçš„é›¶æ—¥æ”»å‡»
        # æ¡ä»¶: åŒæ—¶è¢«åŸºçº¿æ¨¡å‹å’Œé›¶æ—¥æ£€æµ‹å™¨åˆ¤å®šä¸ºå¼‚å¸¸
        results['is_zero_day'] = results['is_baseline_anomaly'] & results['is_zero_day_candidate']
        
        # 7. ğŸ”§ ä¿®å¤ï¼šè®¡ç®—æ›´åˆç†çš„é›¶æ—¥æ”»å‡»åˆ†æ•°
        # åŸºäºå¤šä¸ªå› ç´ çš„ç»¼åˆåˆ†æ•°
        base_score = reconstruction_scores  # åŸºäºé‡å»ºè¯¯å·®çš„å½’ä¸€åŒ–åˆ†æ•°
        
        # åŸºçº¿æ¨¡å‹åˆ†æ•°çš„è´¡çŒ®ï¼ˆå·²å½’ä¸€åŒ–ï¼‰
        baseline_contribution = (results['isolation_forest_score'] + results['kmeans_distance']) / 2
        
        # ç»¼åˆåˆ†æ•°ï¼šé‡å»ºè¯¯å·®æƒé‡æ›´é«˜
        results['zero_day_score'] = 0.7 * base_score + 0.3 * baseline_contribution
        
        # 8. æ–°å¢è§„åˆ™ï¼šæ‰€æœ‰æ¥è‡ªå¤–ç½‘IPçš„æ”»å‡»éƒ½è¢«è®¤ä¸ºæ˜¯é›¶æ—¥æ”»å‡»
        if 'src_ip_is_internal' in results.columns:
            # src_ip_is_internal = 0 è¡¨ç¤ºå¤–ç½‘IPï¼Œ= 1 è¡¨ç¤ºå†…ç½‘IP
            external_ip_attacks = results['src_ip_is_internal'] == 0
            print(f"å‘ç° {external_ip_attacks.sum()} ä¸ªæ¥è‡ªå¤–ç½‘IPçš„æ”»å‡»")
            
            # å°†æ‰€æœ‰å¤–ç½‘IPæ”»å‡»æ ‡è®°ä¸ºé›¶æ—¥æ”»å‡»
            results['is_zero_day'] = results['is_zero_day'] | external_ip_attacks
            
            # å¯¹äºå¤–ç½‘IPæ”»å‡»ï¼Œæå‡åˆ†æ•°ä½†ä¸è¿‡åº¦
            external_mask = external_ip_attacks & (results['zero_day_score'] < 0.7)
            if external_mask.sum() > 0:
                print(f"æå‡ {external_mask.sum()} ä¸ªå¤–ç½‘IPæ”»å‡»çš„é›¶æ—¥åˆ†æ•°")
                results.loc[external_mask, 'zero_day_score'] = np.maximum(
                    results.loc[external_mask, 'zero_day_score'], 
                    0.7  # å¤–ç½‘IPæ”»å‡»çš„æœ€ä½åˆ†æ•°è®¾ä¸º0.7
                )
        else:
            print("è­¦å‘Š: æ— æ³•è·å–IPå†…å¤–ç½‘ä¿¡æ¯ï¼Œæ— æ³•åº”ç”¨å¤–ç½‘IPè§„åˆ™")
        
        # 9. ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_alerts = len(results)
        anomaly_count = sum(results['is_baseline_anomaly'])
        zero_day_count = sum(results['is_zero_day'])
        
        print(f"å…±æ£€æµ‹åˆ° {anomaly_count} ä¸ªå¼‚å¸¸ï¼Œå…¶ä¸­ {zero_day_count} ä¸ªå¯èƒ½æ˜¯é›¶æ—¥æ”»å‡»")
        
        return results
    
    except Exception as e:
        print(f"é›¶æ—¥æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_zero_day_report(df, save_path=None):
    """
    ç”Ÿæˆé›¶æ—¥æ”»å‡»æ£€æµ‹æŠ¥å‘Š
    
    å‚æ•°:
        df: åŒ…å«æ£€æµ‹ç»“æœçš„DataFrame
        save_path: æŠ¥å‘Šä¿å­˜è·¯å¾„
    """
    if df is None:
        print("æ— æ•°æ®å¯ç”ŸæˆæŠ¥å‘Š")
        return
    
    # è·å–å½“å‰è„šæœ¬çš„ç›®å½•å’Œä¿å­˜è·¯å¾„
    if save_path is None:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        data_dir = os.path.join(os.path.dirname(current_dir), "data")
        os.makedirs(data_dir, exist_ok=True)
        save_path = os.path.join(data_dir, f"zero_day_report_{datetime.now().strftime('%Y%m%d')}.csv")
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    df.to_csv(save_path, index=False)
    
    # ç»Ÿè®¡æ£€æµ‹ç»“æœ
    total_alerts = len(df)
    anomaly_alerts = df['is_baseline_anomaly'].sum()
    zero_day_alerts = df['is_zero_day'].sum() if 'is_zero_day' in df.columns else 0
    
    # åˆ›å»ºç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "="*80)
    print("é›¶æ—¥æ”»å‡»æ£€æµ‹æŠ¥å‘Š")
    print("="*80)
    print(f"æ€»å‘Šè­¦æ•°: {total_alerts}")
    print(f"å¼‚å¸¸å‘Šè­¦æ•°: {anomaly_alerts} ({anomaly_alerts/total_alerts*100:.2f}%)")
    print(f"ç–‘ä¼¼é›¶æ—¥æ”»å‡»: {zero_day_alerts} ({zero_day_alerts/total_alerts*100:.2f}%)")
    
    # æŒ‰äº‹ä»¶ç±»å‹ç»Ÿè®¡
    category_field = None
    for field in ['category', 'event_type', 'signature']:
        if field in df.columns:
            category_field = field
            break
    
    if category_field and 'is_zero_day' in df.columns:
        print(f"\næŒ‰{category_field}ç»Ÿè®¡é›¶æ—¥æ”»å‡»:")
        try:
            zero_day_stats = df[df['is_zero_day']].groupby(category_field).size().sort_values(ascending=False)
            print(zero_day_stats.head(10))
        except Exception as e:
            print(f"æŒ‰ç±»å‹ç»Ÿè®¡å‡ºé”™: {e}")
    
    # æŒ‰IPæ¥æºç»Ÿè®¡
    if 'src_ip' in df.columns and 'is_zero_day' in df.columns:
        print("\næŒ‰æ¥æºIPç»Ÿè®¡é›¶æ—¥æ”»å‡»:")
        ip_stats = df[df['is_zero_day']].groupby('src_ip').size().sort_values(ascending=False)
        print(ip_stats.head(10))
    
    # è¾“å‡ºé›¶æ—¥æ”»å‡»ç¤ºä¾‹
    if 'is_zero_day' in df.columns and df['is_zero_day'].sum() > 0:
        print("\nç–‘ä¼¼é›¶æ—¥æ”»å‡»ç¤ºä¾‹:")
        zero_day_samples = df[df['is_zero_day']].sort_values('zero_day_score', ascending=False).head(5)
        for _, alert in zero_day_samples.iterrows():
            src_ip = alert.get('src_ip', 'N/A')
            dst_ip = alert.get('dst_ip', 'N/A')
            if category_field:
                category = alert.get(category_field, 'N/A')
                print(f"- {category} ({src_ip} -> {dst_ip}), é›¶æ—¥åˆ†æ•°: {alert.get('zero_day_score', 0):.4f}")
            else:
                print(f"- å‘Šè­¦ID: {alert.get('id', 'N/A')} ({src_ip} -> {dst_ip}), é›¶æ—¥åˆ†æ•°: {alert.get('zero_day_score', 0):.4f}")
    
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {save_path}")
    return save_path

def save_zero_day_results(db, df):
    """
    å°†é›¶æ—¥æ”»å‡»æ£€æµ‹ç»“æœä¿å­˜åˆ°æ•°æ®åº“
    
    å‚æ•°:
        db: DatabaseConnectorå®ä¾‹
        df: åŒ…å«æ£€æµ‹ç»“æœçš„DataFrame
    """
    if df is None or 'is_zero_day' not in df.columns:
        print("æ²¡æœ‰é›¶æ—¥æ”»å‡»æ£€æµ‹ç»“æœéœ€è¦ä¿å­˜")
        return False
    
    # åªä¿å­˜ç–‘ä¼¼é›¶æ—¥æ”»å‡»çš„è®°å½•
    zero_day_df = df[df['is_zero_day']]
    
    if len(zero_day_df) == 0:
        print("æ²¡æœ‰å‘ç°ç–‘ä¼¼é›¶æ—¥æ”»å‡»")
        return False
    
    # æ·»åŠ æ—¶é—´æˆ³
    zero_day_df['detected_at'] = datetime.now()
    
    # ä¿å­˜åˆ°æ•°æ®åº“ä¸­çš„zero_day_alertsè¡¨
    result = db.save_results(zero_day_df, 'zero_day_alerts', if_exists='append')
    
    if result:
        print(f"æˆåŠŸå°† {len(zero_day_df)} æ¡ç–‘ä¼¼é›¶æ—¥æ”»å‡»è®°å½•ä¿å­˜åˆ°æ•°æ®åº“")
    else:
        print("ä¿å­˜é›¶æ—¥æ”»å‡»æ£€æµ‹ç»“æœå¤±è´¥")
    
    return result

def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œé›¶æ—¥æ”»å‡»æ£€æµ‹æµç¨‹
    """
    start_time = time.time()
    
    # åŠ è½½é…ç½®
    config_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "config", "config.env")
    load_dotenv(config_path)
    
    # ä»é…ç½®è·å–æ£€æµ‹å‚æ•°
    detection_hours = int(os.getenv("ZERODAY_DETECTION_HOURS", 24))  # ä½¿ç”¨å°æ—¶ä½œä¸ºé›¶æ—¥æ£€æµ‹æ—¶é—´å•ä½
    baseline_min_size = int(os.getenv("BASELINE_MIN_SIZE", 100))
    
    print("=" * 80)
    print("é›¶æ—¥æ”»å‡»æ£€æµ‹ç³»ç»Ÿ")
    print(f"é…ç½®æ–‡ä»¶è·¯å¾„: {config_path}")
    print(f"æ£€æµ‹æ—¶é—´èŒƒå›´: æœ€è¿‘{detection_hours}å°æ—¶")
    print(f"åŸºçº¿æ•°æ®æœ€å°è§„æ¨¡: {baseline_min_size}")
    print("=" * 80)
    print()
    
    # 1. åŠ è½½æ¨¡å‹
    print("[1/4] æ­£åœ¨åŠ è½½æ¨¡å‹...")
    preprocessor, if_model, kmeans_model, detector = load_models()
    if preprocessor is None or if_model is None or kmeans_model is None or detector is None:
        print("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ£€æµ‹")
        return
    print()
    
    # 2. è¿æ¥æ•°æ®åº“
    print("[2/4] æ­£åœ¨è¿æ¥æ•°æ®åº“...")
    try:
        db = DatabaseConnector(config_path)
        baseline_data = db.get_baseline_alerts()
        print(f"æˆåŠŸè·å– {len(baseline_data)} æ¡åŸºçº¿å‘Šè­¦æ•°æ®")
    except Exception as e:
        print(f"è¿æ¥æ•°æ®åº“å¤±è´¥: {e}")
        return
    print()
    
    # 3. è·å–æœ€è¿‘çš„å‘Šè­¦æ•°æ®
    print(f"[3/4] æ­£åœ¨è·å–æœ€è¿‘{detection_hours}å°æ—¶çš„å‘Šè­¦æ•°æ®...")
    try:
        end_time = datetime.now()
        start_time_for_query = end_time - timedelta(hours=detection_hours)
        
        print(f"æŸ¥è¯¢æ—¶é—´èŒƒå›´: {start_time_for_query} è‡³ {end_time}")
        
        # ç›´æ¥å°è¯•ä¸€ä¸ªç®€å•çš„SQLæŸ¥è¯¢æ¥æ£€æŸ¥è¡¨ä¸­æ˜¯å¦æœ‰æ•°æ®
        try:
            conn = db.get_connection()
            with conn.cursor() as cursor:
                cursor.execute(f"SELECT COUNT(*) FROM {db.alerts_table}")
                total_count = cursor.fetchone()[0]
                print(f"è¡¨ {db.alerts_table} ä¸­çš„æ€»è®°å½•æ•°: {total_count}")
                
                # æ£€æŸ¥æœ€è¿‘24å°æ—¶æ˜¯å¦æœ‰æ•°æ®
                start_str = start_time_for_query.strftime('%Y-%m-%d %H:%M:%S')
                end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')
                cursor.execute(f"SELECT COUNT(*) FROM {db.alerts_table} WHERE event_time BETWEEN '{start_str}' AND '{end_str}'")
                recent_count = cursor.fetchone()[0]
                print(f"æœ€è¿‘{detection_hours}å°æ—¶çš„è®°å½•æ•°: {recent_count}")
                
                # å¦‚æœæœ€è¿‘24å°æ—¶æ²¡æœ‰æ•°æ®ï¼Œä½†æ€»ä½“æœ‰æ•°æ®ï¼Œæ£€æŸ¥æœ€æ–°çš„è®°å½•æ—¶é—´
                if recent_count == 0 and total_count > 0:
                    cursor.execute(f"SELECT MAX(event_time) FROM {db.alerts_table}")
                    latest_time = cursor.fetchone()[0]
                    print(f"æœ€æ–°è®°å½•çš„event_time: {latest_time}")
                    print(f"å½“å‰ç³»ç»Ÿæ—¶é—´: {datetime.now()}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶åŒºé—®é¢˜
                    time_diff = end_time - latest_time if isinstance(latest_time, datetime) else None
                    if time_diff:
                        print(f"æ—¶é—´å·®å¼‚: {time_diff}")
        except Exception as e:
            print(f"æ‰§è¡Œæ£€æŸ¥SQLå¤±è´¥: {e}")
        
        alerts = db.get_alerts_by_timerange(start_time_for_query, end_time)
        print(f"æˆåŠŸè·å– {len(alerts)} æ¡å‘Šè­¦æ•°æ®")
        
        if alerts.empty or len(alerts) < 1:  # åªè¦æœ‰æ•°æ®å°±å¯ä»¥è¿›è¡Œæ£€æµ‹
            print(f"æ²¡æœ‰å‘Šè­¦æ•°æ®éœ€è¦æ£€æµ‹ï¼Œå½“å‰åªæœ‰ {len(alerts)} æ¡å‘Šè­¦")
            return
            
        # æ•°æ®æ¦‚è§ˆ
        print("æ•°æ®æ¦‚è§ˆ:")
        for col in ['category', 'event_type', 'signature']:
            if col in alerts.columns:
                print(f"- {col}: {len(alerts[col].unique())} ç§")
        
        for col in ['src_ip', 'dst_ip']:
            if col in alerts.columns:
                print(f"- {col}: {len(alerts[col].unique())} ä¸ª")
        
        # æ˜¾ç¤ºæ—¶é—´èŒƒå›´
        if 'event_time' in alerts.columns:
            print(f"- æ—¶é—´èŒƒå›´ (event_time): {alerts['event_time'].min()} è‡³ {alerts['event_time'].max()}")
        
        if 'created_at' in alerts.columns:
            print(f"- æ—¶é—´èŒƒå›´ (created_at): {alerts['created_at'].min()} è‡³ {alerts['created_at'].max()}")
        
        # æ˜¾ç¤ºè¡¨ç»“æ„
        print("\nè¡¨ç»“æ„:")
        print(f"- åˆ—å: {list(alerts.columns)}")
        
        print(f"æˆåŠŸè·å– {len(alerts)} æ¡å‘Šè­¦æ•°æ®")
    except Exception as e:
        print(f"è·å–å‘Šè­¦æ•°æ®å¤±è´¥: {e}")
        return
    print()
    
    # 4. æ£€æµ‹é›¶æ—¥æ”»å‡»
    print("[4/4] æ­£åœ¨è¿›è¡Œé›¶æ—¥æ”»å‡»æ£€æµ‹...")
    results_df = detect_zero_day_attacks(
        alerts, 
        preprocessor, 
        if_model, 
        kmeans_model, 
        detector
    )
    
    if results_df is None or results_df.empty:
        print("æ£€æµ‹å¤±è´¥æˆ–æ²¡æœ‰æ£€æµ‹ç»“æœ")
        return
    
    # 5. ä¿å­˜ç»“æœ
    save_zero_day_results(db, results_df)
    
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    print("\n" + "="*80)
    print("é›¶æ—¥æ”»å‡»æ£€æµ‹å®Œæˆ")
    print(f"æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
    print("="*80)

if __name__ == "__main__":
    main() 